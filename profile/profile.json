{
  "education": [
    {
      "awards_achievements": [
        "Dean's Honour Roll (2024-2025): Faculty of Science"
      ],
      "degree": "Honours Bachelor of Science",
      "department": "Computer Science",
      "duration": "2021-2025",
      "school_name": "Wilfrid Laurier University"
    }
  ],
  "github_repo_root_url": "https://github.com/jarviscanada/jarvis_data_eng_OjuoluwaDabiri",
  "highlighted_projects": [
    {
      "description": "Developed APIs and Kafka consumer pipelines using Java and Spring Boot for Kafka topic data migrations, handling over ten thousand daily client transactions; implemented SQL optimization and microservice refactoring; tested endpoints via Postman and JUnit; deployed through CI CD pipelines in collaboration with DevOps team.",
      "name": "Kafka Consumer Migration"
    },
    {
      "description": "Developed a Python-based predictive model for football match outcomes using Pandas and Scikit-Learn, incorporating extensive preprocessing on multi-season historical match datasets from the last 15 seasons. Evaluated model performance by comparing to actual results over 4 weeks, and by using stratified k-fold cross-validation, reporting metrics such as accuracy, macro-F1, and Brier score, with peak accuracy near 75%.",
      "git_url": "https://github.com/tolani007/EPL-WinPredictor",
      "name": "Premier League Machine Learning Model"
    },
    {
      "description": "Designed and Architected an end-to-end data pipeline in Databricks to collect, clean, and transform Premier League match data; implemented ETL workflows with PySpark and Delta Lake; tested data quality using SQL and visualization dashboards; deployed interactive insights to Power BI and Tableau for real-time performance tracking.",
      "git_url": "https://github.com/OJ-Dabiri/MUFCEfficiencyETL",
      "name": "Databricks Premier League Data Pipeline"
    }
  ],
  "jarvis_projects": [
    {
      "description": "Developed a Linux-based resource monitoring agent that collects, stores, and analyzes real-time system metrics across multiple servers . Implemented using Bash scripts, PostgreSQL, and cron automation; scripted SQL queries for performance reporting and integrated Docker for deployment consistency.",
      "git_url": "/linux_sql",
      "name": "Cluster Monitor"
    },
    {
      "description": "Grep App - Implemented a simplified version of the Unix grep command in Java. The application recursively searches a directory, reads each file line-by-line, applies a user-defined regex pattern, and writes all matching lines to an output file. The app uses several core software engineering concepts including Java OOP design and I/O, regular expressions, and Stream APIs.\"",
      "git_url": "/core_java",
      "name": "Core Java Apps"
    }
  ],
  "name": "Ojuoluwa Dabiri",
  "others": [
    {
      "bullets": [
        "Google Professional Advanced Data Analysis Certification (2024)"
      ],
      "title": "Certificates"
    },
    {
      "bullets": [
        "Teaching Assistant (Undergraduate)",
        "Competitive Soccer (Grand River Soccer League)"
      ],
      "title": "Activities/Hobbies"
    }
  ],
  "professional_experience": [
    {
      "company": "Jarvis",
      "description": "Designing and building full stack and data driven software solutions within an Agile development environment, collaborating with engineers, product leads, and data specialists to architect scalable backend systems, develop RESTful APIs, and automate pipelines that improve system reliability and performance. Working hands on with Java, Python, and SQL to implement clean, maintainable code across multiple projects while contributing to sprint planning, code reviews, and CI CD workflows using Git, Docker, and cloud services.",
      "duration": "October 2025-present",
      "title": "Software Developer"
    },
    {
      "company": "Moneris",
      "description": "Developed and Deployed RESTful backend APIs and microservices using Java and Spring Boot, contributing to business-facing API development that served over 10,000 client transactions daily. Improved payment API response times by up to 25% by optimizing Apache Kafka consumer pipelines and Node.js backend services, while refactoring inefficient endpoints in collaboration with the core app team. Collaborated with QA and DevOps to execute unit tests and deploy new application features across Agile sprints using CI/CD pipelines. Accelerated deployment cycles by integrating Git-based version control, automated build pipelines, and standardized release management processes.",
      "duration": "May 2023 - May 2024",
      "title": "Software Developer"
    },
    {
      "company": "Kinesii",
      "description": "Automated routine diagnostics using PowerShell scripts, reducing help-desk manual troubleshooting time. Managed unit test and SaaS deployment using Docker and GCP Cloud Run, independently creating a test environment for service deployment and integrating it into a lightweight CI/CD pipeline using GitHub Actions. Coordinated customer solution implementation and system installations both remotely and on-site. Collaborated with consultants and IT leadership to implement system upgrades within defined timelines.",
      "duration": "June 2022 - April 2023",
      "title": "QA Support Analyst"
    }
  ],
  "skills": {
    "competent": [
      "Amazon Web Services",
      "JUnit Testing",
      "Bash Scripting",
      "Microsoft Azure",
      "C++"
    ],
    "familiar": [
      "C#",
      "React",
      "Flask",
      "Selenium",
      "Swift"
    ],
    "proficient": [
      "Java",
      "Spring Boot",
      "RDBMS/SQL",
      "Apache Kafka",
      "Docker",
      "Kubernetes"
    ]
  },
  "summary": "I am a software developer with a strong foundation in backend engineering, data analytics, and fintech systems. My professional experience at Moneris allowed me to design and deploy RESTful APIs, optimize Spring Boot microservices, and enhance Kafka based pipelines that supported thousands of daily client transactions. I have built efficient SQL workflows, automated testing environments, and collaborated across Agile teams to maintain reliable CI and CD deployments. Alongside industry experience, I have developed a deep understanding of modern software ecosystems through my Computer Science degree at Wilfrid Laurier University, where I was able to apply my critical and architectural reasoning skills through advanced coursework and hands on projects in machine learning, system design, and data visualization. I value teamwork, continuous learning, and thoughtful engineering. I am driven by curiosity. Whether exploring scalable software infrastructure, improving developer workflows, or mentoring peers, I aim to keep growing into a well rounded developer who builds technology that simplifies systems and delivers measurable impact."
}
